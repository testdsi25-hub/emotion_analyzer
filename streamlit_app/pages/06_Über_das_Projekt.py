# Bibliothek
import streamlit as st

st.title("ğŸ“ Ãœber das Projekt")

with st.expander("ğŸ§  1. Elevator Pitch"):

    st.markdown("**Diese App macht hÃ¶rbare Emotionen sichtbar.**")
    st.markdown(
        """
        Sie schafft eine intuitive Umgebung, in der Nutzerinnen und Nutzer Audiodaten des RAVDESS-Datensatzes gezielt untersuchen und besser verstehen kÃ¶nnen. Ein zentrales Dashboard zeigt den Datensatz Ã¼bersichtlich und strukturiert. Mit dem Audio Explorer lassen sich Sprachaufnahmen direkt abspielen und durchstÃ¶bern. Die Feature Analysis legt akustische Merkmale wie Frequenzverteilungen oder MFCCs offen und hilft, Muster zu erkennen. Der Visualizer bringt emotionale Eigenschaften grafisch auf den Punkt und macht sie unmittelbar erfahrbar.
        Ein Machine-Learning-basiertes Modul zur automatischen Emotionserkennung erweitert die Anwendung um die FÃ¤higkeit, GefÃ¼hle direkt aus Sprache zu erfassen.

        Ob in der Forschung, Produktentwicklung oder im Bereich Human-Machine Interaction baut diese LÃ¶sung eine BrÃ¼cke zwischen Klang und GefÃ¼hl.
        """
    )

with st.expander("ğŸ¯ 2. Ziel & Nutzen"):

    st.markdown(
        """
        Das Hauptziel dieser App ist es, hÃ¶rbare Emotionen greifbar zu machen und zwar visuell, analytisch und intuitiv. Sie erÃ¶ffnet einen neuen Zugang zur Welt der emotionalen Sprache, indem sie komplexe Audiodaten nicht nur darstellt, sondern auch verstÃ¤ndlich macht.
        """
    )
    st.markdown(
        """
        Die Anwendung bietet:

        - **Strukturierte Ãœbersicht:** Ein zentrales Dashboard schafft Klarheit im RAVDESS-Datensatz und erleichtert die gezielte Navigation.

        - **Direkten Zugang zu Sprache:** Mit dem Audio Explorer lassen sich Aufnahmen unmittelbar erleben und vergleichen.

        - **Tiefe Einblicke in akustische Merkmale:** Die Feature Analysis legt die klanglichen Grundlagen emotionaler Sprache von Frequenzverteilungen bis hin zu MFCCs offen.

        - **Emotionale Visualisierung:** Der Visualizer Ã¼bersetzt GefÃ¼hle in anschauliche Grafiken und macht emotionale Nuancen sichtbar.

        - **Automatisierte Emotionserkennung:** Ein Machine-Learning-Modul erkennt GefÃ¼hle direkt aus Sprache und erweitert die Analyse um eine intelligente Komponente.
        """)

    st.markdown(
        """
        Ziel der App ist es, Ã¼berall dort einen Mehrwert zu schaffen, wo Sprache und GefÃ¼hl aufeinandertreffen, sei es fÃ¼r wissenschaftliche Studien, die Entwicklung empathischer Technologien oder die Verbesserung von Mensch-Maschine-Kommunikation. 
        """
    )

with st.expander("ğŸ” 3. FunktionsÃ¼bersicht"):

    st.markdown(
        """

        ğŸ“Š Dashboard â€“ Ãœberblick Ã¼ber den Datensatz

        ğŸ§ Audio Explorer â€“ Audiodateien anhÃ¶ren und erkunden

        ğŸ” Feature Analysis â€“ Analyse akustischer Eigenschaften

        ğŸ¨ Visualizer â€“ Emotionale Merkmale einzelner Sprachaufnahmen visuell darstellen

        â¤ï¸ Emotion Analyzer â€“ Emotionserkennung via ML (Demo)
        """
    )

with st.expander("ğŸ§¬ 4. Technologie & Methodik"):

    st.markdown(
        """
       Die App basiert auf einem modularen Technologie-Stack, der moderne Machine-Learning-AnsÃ¤tze mit interaktiver Visualisierung verbindet. Zur Klassifikation emotionaler ZustÃ¤nde kommen sowohl klassische Modelle als auch Deep-Learning-Architekturen zum Einsatz. Die Analyse akustischer Merkmale erfolgt Ã¼ber bewÃ¤hrte Verfahren wie MFCCs, Zero-Crossing Rate und Spektralanalyse, um emotionale Nuancen in Stimme und Sprechweise zu erfassen. Die Ergebnisse werden in Echtzeit Ã¼ber ein mit Streamlit entwickeltes Interface visualisiert, das eine intuitive und explorative Nutzung ermÃ¶glicht. So entsteht ein leistungsfÃ¤higes Werkzeug zur datengetriebenen Interpretation von hÃ¶rbaren Emotionen.
        """
    )

with st.expander("ğŸ‘¥ 5. Zielgruppen & Anwendungsszenarien"):

    st.markdown(
        """
        Diese App richtet sich an alle, die sich mit der emotionalen Dimension von Sprache beschÃ¤ftigen, sei es wissenschaftlich, gestalterisch oder kreativ. Sie bietet Werkzeuge, die sowohl analytisch als auch intuitiv nutzbar sind und schafft damit eine vielseitige Plattform fÃ¼r unterschiedlichste Anwendungsbereiche:

        - Forschende in Psychologie, Linguistik und KI kÃ¶nnen sie nutzen, um emotionale Sprachmuster zu untersuchen, bestehende Hypothesen zu validieren oder neue Modelle der Sprachverarbeitung zu entwickeln. Denkbar wÃ¤re, dass emotionale Sprachmuster psychische Erkrankungen, wie Depression, AngststÃ¶rung oder ADHS, frÃ¼hzeitig erkennen lassen und somit die Erfolgsquote der Therapie steigert. 

        - UX-Designerinnen und -designer sowie Entwicklerinnen und Entwickler kÃ¶nnen mit Hilfe von emotionaler Spracherkennung dafÃ¼r sorgen, dass digitale Produkte GefÃ¼hle besser wahrnehmen und darauf reagieren. Ein Beispiel wÃ¤re, dass eine Anwendung erkennt, ob jemand gestresst, ruhig oder frustriert spricht und sich entsprechend anpasst.   

        - KÃ¼nstlerinnen und KÃ¼nstler, Musikerinnen und Musiker sowie Therapeutinnen und Therapeuten kÃ¶nnen einen Emotion Analyzer als Inspirationsquelle, Reflexionsraum oder Werkzeug zur Arbeit mit Klang, GefÃ¼hl und Ausdruck verwenden. Wenn Studierende in ihrer Schauspielausbildung ihren emotionalen Ausdruck trainieren, wÃ¼rden sie vom Modell eine unmittelbare RÃ¼ckmeldung bekommen, ob sie die gewÃ¼nschte Emotion getroffen haben.

        - Expertinnen und Experten in Medienanalyse und Content-Moderation kÃ¶nnen mit der App gesprochene Sprache gezielt auf emotionale Muster untersuchen. So kÃ¶nnen sie bei Interviews die emotionale TonalitÃ¤t besser erkennen, frÃ¼hzeitig emotionale Eskalationen entgegensteuern oder sensiblere Moderationsstrategien entwickeln.

        - Politikerinnen und Politiker kÃ¶nnen die App einsetzen, um die emotionale Wirkung ihrer Reden gezielt zu analysieren und zu optimieren. Sie erhalten Einblicke in die akustischen Merkmale ihrer Sprache und kÃ¶nnen nachvollziehen, wie bestimmte Tonlagen oder Ausdrucksweisen beim Publikum ankommen. In der strategischen Kommunikation lÃ¤sst sich so die emotionale Resonanz steigern, sei es im Wahlkampf, bei Krisenansprachen oder in parlamentarischen Debatten. DarÃ¼ber hinaus kann die App helfen, BÃ¼rgerreaktionen auf politische Botschaften besser zu verstehen und infolgedessen die Ansprache empathischer und zielgerichteter zu gestalten.
        """
    )

    st.markdown(
    """
    Die App soll den verschiedenen Zielgruppen ein Fenster in die Welt der hÃ¶rbaren Emotionen Ã¶ffnen und sie dazu einladen, emotionalen Klang in Sprache neu zu denken.
    """        
    )

with st.expander("ğŸš€ 6. Vision & Ausblick"):

    st.markdown(
        """
        Diese App ist der erste Schritt in eine Zukunft, in der Maschinen nicht nur zuhÃ¶ren, sondern mitfÃ¼hlen. 
        """
    )
    st.markdown(
        """
        Langfristig soll die Spracherkennung in Echtzeit emotionale ZustÃ¤nde erfassen, feinere GefÃ¼hlsnuancen unterscheiden und sich nahtlos in bestehende Plattformen integrieren, von Therapie-Tools Ã¼ber Assistenzsysteme bis hin zu kreativen Anwendungen. 
        """)
    st.markdown(
        """
        Die Vision ist eine Technologie, die Klang in Empathie verwandelt und emotionale Intelligenz zum festen Bestandteil digitaler Kommunikation macht.
        """
    )
    
with st.expander("ğŸ“ 7. Team & Kontakt"):

    st.markdown("#### ğŸ‘¥ Das Team hinter der App")
    
    st.markdown(
        """
    Wir sind Marco, Fabian und Eva, drei Datenbegeisterte mit ganz unterschiedlichem Hintergrund, aber einer gemeinsamen Mission: 
    Emotionen in Sprache sichtbar zu machen.
    
    ğŸ¼ **Eva** kommt aus der Musikwissenschaft und bringt ein feines GespÃ¼r fÃ¼r Klang und Ausdruck mit. Ihre auditive Erfahrung hilft unseren Modellen, den richtigen Ton zu finden und wennâ€™s um Zahlen geht, verwandelt sie Sprachaufnahmen in Diagramme, die mehr sagen als tausend Worte.
    
    ğŸ“Š **Fabian** kommt aus der Politik und bringt Ordnung in unsere Datenwelt. Mit klassischen Machine-Learning-AnsÃ¤tzen sorgt er fÃ¼r Modelle, die nicht nur funktionieren, sondern auch verstÃ¤ndlich bleiben. Fabian ist unser diplomatischer Datenlenker mit klaren Linien und nachvollziehbarer Logik.
    
    ğŸŒ¾ **Marco** hat seine Wurzeln in den Agrarwissenschaften und bringt ein tiefes VerstÃ¤ndnis fÃ¼r natÃ¼rliche Prozesse mit. Er entwickelt Deep-Learning-Modelle, die mit maximaler Effizienz GefÃ¼hle erkennen â€“ wie ein prÃ¤ziser Bodenanalytiker fÃ¼r emotionale Landschaften. Wennâ€™s um neuronale Netze geht, ist Marco unser Wachstumsexperte mit grÃ¼nem Daumen fÃ¼rs Digitale.
    
    Kennengelernt haben wir uns am Data Science Institute in Berlin â€“ zwischen Codezeilen, fehlenden Kaffeepausen und der Erkenntnis, dass Emotionen in Daten mehr sind als nur Zahlen. In unserem Projekt wollen wir Technik mit Empathie verbinden.
    
    Inzwischen erkennen unsere Modelle 8 emotionale ZustÃ¤nde â€“ auÃŸer den, wenn das WLAN ausfÃ¤llt. Da hilft nur noch echter menschlicher Trost. ğŸ˜… 
     """
    )
    
    st.markdown("#### ğŸ“§ Kontakt")
    st.markdown("""
                RÃ¼ckmeldungen oder Anfragen bitte an unsere digitale Assistenz: 
    
                K.I. Feelgood 
    
                ğŸ’Œ KI@feelgood.com 
                
                """
                )