# Bibliothek
import streamlit as st

# Import der eigenen Module
from utils import metadata_parser as mp
from utils import audio_features as af
from utils import visualisation as vis

# Konfiguration der Seite
st.set_page_config(
    page_title="Visualizer",
    page_icon="ğŸ¨",
    layout="wide"
)

# Hauptfunktion der Seite
def main():
    st.title("ğŸ¨ Visualizer einzelner Audio-Dateien")    
    st.info("ğŸ” **Fokus dieser Seite:** Technische Visualisierung einzelner Audio-Signale (Wellenform, Spektrogramme, Pitch-Tracking)")
    
    # Sidebar fÃ¼r Konfiguration (gleich wie Audio Features)
    with st.sidebar:
        st.header("âš™ï¸ Konfiguration")
        data_path = "data/ravdess"
        st.markdown(f"**Datenpfad:** `{data_path}`")
        st.divider()
    
    # Metadaten laden
    with st.spinner("ğŸ”„ Lade RAVDESS-Metadaten..."):
        try:
            metadata_df = mp.load_ravdess_metadata(data_path)
            
            if metadata_df.empty:
                st.error("âŒ Keine gÃ¼ltigen RAVDESS-Dateien gefunden.")
                st.stop()
                
            st.success(f"âœ… {len(metadata_df)} Audiodateien gefunden!")
            
        except Exception as e:
            st.error(f"âŒ Fehler beim Laden der Metadaten: {str(e)}")
            st.stop()
    
    # Hinweis zu Features Analysis
    st.markdown("""
    ğŸ’¡ **Tipp:** FÃ¼r statistische Analysen und Vergleiche zwischen Emotionen besuchen Sie die **Feature Analysis**, siehe **Seitenleiste**.
    """)
    
    # Dateiauswahl
    st.divider()
    st.subheader("ğŸ¯ Datei auswÃ¤hlen")
    
    # Filter-Optionen
    col1, col2, col3 = st.columns(3)
    
    with col1:
        selected_emotion = st.selectbox(
            "ğŸ­ Emotion filtern:",
            options=['Alle'] + sorted(metadata_df['emotion'].unique().tolist())
        )
    
    with col2:
        selected_gender = st.selectbox(
            "ğŸ‘¥ Geschlecht filtern:",
            options=['Alle'] + sorted(metadata_df['gender'].unique().tolist())
        )
    
    with col3:
        selected_intensity = st.selectbox(
            "ğŸšï¸ IntensitÃ¤t filtern:",
            options=['Alle'] + sorted(metadata_df['intensity'].unique().tolist())
        )
    
    # DataFrame filtern
    filtered_df = metadata_df.copy()
    
    if selected_emotion != 'Alle':
        filtered_df = filtered_df[filtered_df['emotion'] == selected_emotion]
    if selected_gender != 'Alle':
        filtered_df = filtered_df[filtered_df['gender'] == selected_gender]
    if selected_intensity != 'Alle':
        filtered_df = filtered_df[filtered_df['intensity'] == selected_intensity]
    
    if filtered_df.empty:
        st.warning("âš ï¸ Keine Dateien entsprechen den gewÃ¤hlten Filtern.")
        st.stop()
    
    # Dateiauswahl-Dropdown
    file_options = []
    for _, row in filtered_df.iterrows():
        display_name = f"{row['emotion'].title()} - {mp.GENDER_DISPLAY_MAP.get(row['gender'])} - Actor {row['actor_id']:02d} - {row['filename']}"
        file_options.append((display_name, row['file_path'], dict(row)))
    
    selected_display, selected_path, selected_metadata = st.selectbox(
        "ğŸµ Audiodatei wÃ¤hlen:",
        options=file_options,
        format_func=lambda x: x[0]
    )
    
    # Audio-Player
    st.markdown("##### ğŸ§ Audio-Wiedergabe")
    try:
        audio_file = open(selected_path, 'rb')
        audio_bytes = audio_file.read()
        st.audio(audio_bytes, format='audio/wav')
    except Exception as e:
        st.error(f"âŒ Fehler beim Laden der Audiodatei: {str(e)}")
    
    # Metadaten anzeigen
    st.markdown("---")
    st.markdown("### â„¹ï¸ Information zur gewÃ¤hlten Audio-Datei")
    mp.display_audio_metadata(selected_metadata)
    
    # Audio-Features extrahieren
    st.markdown("---")
    st.subheader("ğŸ”§ Feature-Extraktion")
    
    with st.spinner("ğŸ”„ Extrahiere Audio-Features..."):
        features = af.extract_audio_features(selected_path)
        
        if features:
            mp.display_extracted_features(features)
        else:
            st.error("âŒ Fehler bei der Feature-Extraktion.")
            st.stop()
    
    # Audio-Visualisierungen
    st.subheader("ğŸ“Š Audio-Visualisierungen")
    
    # Lade Audiodaten fÃ¼r Visualisierung
    with st.spinner("ğŸ”„ Berechne Visualisierungen..."):
        audio_data = mp.load_audio_data(selected_path)
        
        if audio_data is None:
            st.error("âŒ Fehler beim Laden der Audiodaten fÃ¼r Visualisierung.")
            st.stop()
    
    # Tab-Layout fÃ¼r verschiedene Visualisierungen
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‰ Wellenform", "ğŸŒˆ Mel-Spektrogramm", "ğŸ”¥ MFCC-Heatmap", "ğŸ¼ Pitch-Tracking"])
    
    with tab1:
        st.markdown("""
        **ğŸ“‰ Wellenform:** Zeigt die Amplitude (LautstÃ¤rke) der Audiodatei Ã¼ber die Zeit. 
        Hohe Peaks bedeuten laute Abschnitte, niedrige Werte sind leise Passagen.
        """)
        waveform_fig = vis.create_waveform_plot(audio_data)
        st.plotly_chart(waveform_fig, use_container_width=True)

         # Interpretationshilfe
        st.subheader("ğŸ’¡ Signal-Interpretationshilfe")

        with st.expander("ğŸ¤” Wie interpretiere ich dieses Audio-Signal?"):
            st.markdown("""
            ### ğŸ“‰ Wellenform (Amplitude Ã¼ber Zeit)
            - **Hohe Peaks**: Laute Silben oder Betonungen
            - **Niedrige Bereiche**: Pausen oder leise Passagen
            - **GleichmÃ¤ÃŸige Amplitude**: Ruhiges, kontrolliertes Sprechen
            - **UnregelmÃ¤ÃŸige Amplitude**: Emotionale oder aufgeregte Sprache
                        """)

    with tab2:
        st.markdown("""
        **ğŸŒˆ Mel-Spektrogramm:** Visualisiert die Frequenzen Ã¼ber die Zeit in einer fÃ¼r das menschliche GehÃ¶r optimierten Skala. 
        Hellere Bereiche zeigen stÃ¤rkere Frequenzkomponenten. Vertikale Linien sind oft Konsonanten, horizontale BÃ¤nder Vokale.
        """)
        mel_spec_fig = vis.create_mel_spectrogram_plot(audio_data)
        st.plotly_chart(mel_spec_fig, use_container_width=True)

        # Interpretationshilfe
        st.subheader("ğŸ’¡ Signal-Interpretationshilfe")

        with st.expander("ğŸ¤” Wie interpretiere ich dieses Audio-Signal?"):
            st.markdown("""
            ### ğŸŒˆ Mel-Spektrogramm (Frequenz-Zeit-Analyse)
            - **Horizontale BÃ¤nder**: Vokale (a, e, i, o, u) mit charakteristischen Formanten
            - **Vertikale Linien**: Konsonanten mit kurzer, breitbandiger Energie
            - **Helle untere Bereiche**: Grundfrequenz und ObertÃ¶ne
            - **Dunkle Bereiche**: Geringe Energie in diesen Frequenzbereichen
                        """)
    
    with tab3:
        st.markdown("""
        **ğŸ”¥ MFCC-Heatmap:** Zeigt die 13 wichtigsten spektralen Merkmale Ã¼ber die Zeit. 
        MFCC-Koeffizienten erfassen die charakteristische "Klangfarbe" der Stimme und sind essentiell fÃ¼r Spracherkennung.
        """)
        mfcc_fig = vis.create_mfcc_heatmap_plot(audio_data)
        st.plotly_chart(mfcc_fig, use_container_width=True)

        # Interpretationshilfe
        st.subheader("ğŸ’¡ Signal-Interpretationshilfe")
        
        with st.expander("ğŸ¤” Wie interpretiere ich dieses Audio-Signal?"):
            st.markdown("""
            ### ğŸ”¥ MFCC-Heatmap (Spektrale Koeffizienten)
            - **MFCC 1**: Gesamtenergie des Signals
            - **MFCC 2-4**: Charakteristische Sprachmerkmale
            - **MFCC 5-13**: Feinere spektrale Details
            - **Rot/Warm**: Positive Werte, **Blau/Kalt**: Negative Werte
                        """)
    
    with tab4:
        st.markdown("""
        **ğŸ¼ Pitch-Tracking:** Verfolgt die Grundfrequenz (TonhÃ¶he) der Stimme Ã¼ber die Zeit. 
        HÃ¶here Werte bedeuten hÃ¶here Stimme, SprÃ¼nge zeigen IntonationsÃ¤nderungen. Emotionen beeinflussen oft das Pitch-Muster.
        """)
        pitch_fig = vis.create_pitch_plot(audio_data)
        st.plotly_chart(pitch_fig, use_container_width=True)
        # Interpretationshilfe
        st.subheader("ğŸ’¡ Signal-Interpretationshilfe")

        with st.expander("ğŸ¤” Wie interpretiere ich dieses Audio-Signal?"):
            st.markdown("""
            ### ğŸ¼ Pitch-Tracking (Grundfrequenz)
            - **Konstante Linien**: Monotone Sprache
            - **AufwÃ¤rts-Trends**: Fragende Intonation
            - **AbwÃ¤rts-Trends**: AussagesÃ¤tze
            - **SprÃ¼nge**: Emotionale Betonung oder Wortgrenzen
                        """)

if __name__ == "__main__":
    main()